#!/bin/bash
#SBATCH --partition=gpu
#SBATCH --gpus=4
#SBATCH --job-name=DiscreteActionMultigpu
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=05:00:00
#SBATCH --output=discrete-action_output_multi_gpu_%A.out

module purge
module load 2022
module load Anaconda3/2022.05

# Activate environment
source activate recsys

# Path of framework
FW=$HOME/Prompt4NR
TEMPLATE=$FW/Discrete-Action

# Change directory to the model template
cd $TEMPLATE

# Copy datasets to temp folder to save read/write operations computational costs
export DATA_SET=/ebnerd

if [ ! -d "$TMPDIR$DATA_SET" ]; then
    mkdir $TMPDIR$DATA_SET
fi

rsync -a $FW/DATA$DATA_SET/ $TMPDIR$DATA_SET

# Check whether the GPU is available
# srun python -uc "import torch; print('GPU available?', torch.cuda.is_available())"

# Run python scripts that train model and predicts. Content of run_py3.sh
srun python3 -u main-multigpu.py --data_path $TMPDIR$DATA_SET --model_name bert-base-multilingual-uncased --epochs 3 --batch_size 16 --test_batch_size 100 --wd 1e-3 --max_tokens 500 --log True --model_save True
srun python3 -u predict.py --data_path $TMPDIR$DATA_SET --model_name bert-base-multilingual-uncased --test_batch_size 100 --max_tokens 500 --model_file ./temp/BestModel.pt --log True
